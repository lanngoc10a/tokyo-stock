{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lan/Downloads/Github/tokyo-stock'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_files/stock_prices.csv\")\n",
    "#df= pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170104_1333</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1333</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170104_1376</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1376</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170104_1377</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1377</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RowId        Date  SecuritiesCode    Open    High     Low   Close  \\\n",
       "0  20170104_1301  2017-01-04            1301  2734.0  2755.0  2730.0  2742.0   \n",
       "1  20170104_1332  2017-01-04            1332   568.0   576.0   563.0   571.0   \n",
       "2  20170104_1333  2017-01-04            1333  3150.0  3210.0  3140.0  3210.0   \n",
       "3  20170104_1376  2017-01-04            1376  1510.0  1550.0  1510.0  1550.0   \n",
       "4  20170104_1377  2017-01-04            1377  3270.0  3350.0  3270.0  3330.0   \n",
       "\n",
       "    Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag    Target  \n",
       "0    31400               1.0               NaN            False  0.000730  \n",
       "1  2798500               1.0               NaN            False  0.012324  \n",
       "2   270800               1.0               NaN            False  0.006154  \n",
       "3    11300               1.0               NaN            False  0.011053  \n",
       "4   150800               1.0               NaN            False  0.003026  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2332531, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train=df[df.SecuritiesCode==1332]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>20170105_1332</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>1332</td>\n",
       "      <td>572.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>2162900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.022609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>20170106_1332</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1332</td>\n",
       "      <td>567.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>2125600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.016014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>20170110_1332</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>1332</td>\n",
       "      <td>573.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>2744600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7461</th>\n",
       "      <td>20170111_1332</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>1332</td>\n",
       "      <td>559.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>2231800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322532</th>\n",
       "      <td>20211129_1332</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>1332</td>\n",
       "      <td>579.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1607200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324532</th>\n",
       "      <td>20211130_1332</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>1332</td>\n",
       "      <td>580.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2732300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326532</th>\n",
       "      <td>20211201_1332</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1661300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328532</th>\n",
       "      <td>20211202_1332</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>1332</td>\n",
       "      <td>566.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>1525800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330532</th>\n",
       "      <td>20211203_1332</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1332</td>\n",
       "      <td>579.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1195500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.056027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowId        Date  SecuritiesCode   Open   High    Low  \\\n",
       "1        20170104_1332  2017-01-04            1332  568.0  576.0  563.0   \n",
       "1866     20170105_1332  2017-01-05            1332  572.0  573.0  565.0   \n",
       "3731     20170106_1332  2017-01-06            1332  567.0  576.0  563.0   \n",
       "5596     20170110_1332  2017-01-10            1332  573.0  576.0  561.0   \n",
       "7461     20170111_1332  2017-01-11            1332  559.0  562.0  551.0   \n",
       "...                ...         ...             ...    ...    ...    ...   \n",
       "2322532  20211129_1332  2021-11-29            1332  579.0  579.0  567.0   \n",
       "2324532  20211130_1332  2021-11-30            1332  580.0  590.0  573.0   \n",
       "2326532  20211201_1332  2021-12-01            1332  568.0  578.0  568.0   \n",
       "2328532  20211202_1332  2021-12-02            1332  566.0  577.0  565.0   \n",
       "2330532  20211203_1332  2021-12-03            1332  579.0  585.0  570.0   \n",
       "\n",
       "         Close   Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
       "1        571.0  2798500               1.0               NaN            False   \n",
       "1866     568.0  2162900               1.0               NaN            False   \n",
       "3731     575.0  2125600               1.0               NaN            False   \n",
       "5596     562.0  2744600               1.0               NaN            False   \n",
       "7461     553.0  2231800               1.0               NaN            False   \n",
       "...        ...      ...               ...               ...              ...   \n",
       "2322532  567.0  1607200               1.0               NaN            False   \n",
       "2324532  573.0  2732300               1.0               NaN            False   \n",
       "2326532  574.0  1661300               1.0               NaN            False   \n",
       "2328532  573.0  1525800               1.0               NaN            False   \n",
       "2330532  585.0  1195500               1.0               NaN            False   \n",
       "\n",
       "           Target  \n",
       "1        0.012324  \n",
       "1866    -0.022609  \n",
       "3731    -0.016014  \n",
       "5596    -0.016275  \n",
       "7461     0.016544  \n",
       "...           ...  \n",
       "2322532  0.001745  \n",
       "2324532 -0.001742  \n",
       "2326532  0.020942  \n",
       "2328532  0.006838  \n",
       "2330532 -0.056027  \n",
       "\n",
       "[1202 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.SecuritiesCode==1332]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01232394366197183"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(575.0- 568.0)/568.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.preprocessing.MinMaxScaler.fit_transform(df[[column]]) to return the Pandas DataFrame df from the first step with the specified column min-max scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set == (1202, 5).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.68000000e+02,  5.76000000e+02,  5.63000000e+02,\n",
       "         5.71000000e+02,  1.23239437e-02],\n",
       "       [ 5.72000000e+02,  5.73000000e+02,  5.65000000e+02,\n",
       "         5.68000000e+02, -2.26086957e-02],\n",
       "       [ 5.67000000e+02,  5.76000000e+02,  5.63000000e+02,\n",
       "         5.75000000e+02, -1.60142349e-02],\n",
       "       ...,\n",
       "       [ 5.68000000e+02,  5.78000000e+02,  5.68000000e+02,\n",
       "         5.74000000e+02,  2.09424084e-02],\n",
       "       [ 5.66000000e+02,  5.77000000e+02,  5.65000000e+02,\n",
       "         5.73000000e+02,  6.83760684e-03],\n",
       "       [ 5.79000000e+02,  5.85000000e+02,  5.70000000e+02,\n",
       "         5.85000000e+02, -5.60271647e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[\"Open\",\"High\", \"Low\", \"Close\", \"Target\"]\n",
    "\n",
    "dataset_train = dataset_train[cols].astype(float).reset_index()\n",
    "\n",
    "training_set = dataset_train[cols].values\n",
    "\n",
    "# Using multiple features (predictors)\n",
    "#training_set = dataset_train.as_matrix()\n",
    "\n",
    "print('Shape of training set == {}.'.format(training_set.shape))\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1866</td>\n",
       "      <td>572.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>-0.022609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3731</td>\n",
       "      <td>567.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>-0.016014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5596</td>\n",
       "      <td>573.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>-0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7461</td>\n",
       "      <td>559.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>0.016544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2322532</td>\n",
       "      <td>579.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2324532</td>\n",
       "      <td>580.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>-0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2326532</td>\n",
       "      <td>568.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.020942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2328532</td>\n",
       "      <td>566.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>0.006838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>2330532</td>\n",
       "      <td>579.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>-0.056027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   Open   High    Low  Close    Target\n",
       "0           1  568.0  576.0  563.0  571.0  0.012324\n",
       "1        1866  572.0  573.0  565.0  568.0 -0.022609\n",
       "2        3731  567.0  576.0  563.0  575.0 -0.016014\n",
       "3        5596  573.0  576.0  561.0  562.0 -0.016275\n",
       "4        7461  559.0  562.0  551.0  553.0  0.016544\n",
       "...       ...    ...    ...    ...    ...       ...\n",
       "1197  2322532  579.0  579.0  567.0  567.0  0.001745\n",
       "1198  2324532  580.0  590.0  573.0  573.0 -0.001742\n",
       "1199  2326532  568.0  578.0  568.0  574.0  0.020942\n",
       "1200  2328532  566.0  577.0  565.0  573.0  0.006838\n",
       "1201  2330532  579.0  585.0  570.0  585.0 -0.056027\n",
       "\n",
       "[1202 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65001496],\n",
       "       [-1.2162423 ],\n",
       "       [-0.86393682],\n",
       "       ...,\n",
       "       [ 1.11045175],\n",
       "       [ 0.3569104 ],\n",
       "       [-3.00160584]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#sc = MinMaxScaler(feature_range=(0,1))\n",
    "#training_set_scaled = sc.fit_transform(training_set[:, 4:5])\n",
    "\n",
    "sc = StandardScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "sc_predict = StandardScaler()\n",
    "sc_predict.fit_transform(training_set[:, 4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18042079, -0.1577142 , -0.16511377, -0.14393996,  0.65001496],\n",
       "       [-0.13486516, -0.19160483, -0.14213959, -0.17812012, -1.2162423 ],\n",
       "       [-0.1918097 , -0.1577142 , -0.16511377, -0.0983664 , -0.86393682],\n",
       "       ...,\n",
       "       [-0.18042079, -0.13512044, -0.10767832, -0.10975979,  1.11045175],\n",
       "       [-0.20319861, -0.14641732, -0.14213959, -0.12115318,  0.3569104 ],\n",
       "       [-0.0551428 , -0.0560423 , -0.08470414,  0.01556749, -3.00160584]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (1171, 30, 5).\n",
      "y_train shape == (1171, 1).\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 2   # Number of days we want top predict into the future\n",
    "n_past = 30     # Number of past days we want to use to predict the future\n",
    "\n",
    "\n",
    "for i in range(n_past, len(training_set_scaled) - n_future +1):\n",
    "    X_train.append(training_set_scaled[i - n_past:i, 0:dataset_train.shape[1] - 1])\n",
    "    y_train.append(training_set_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "    \n",
    "#for i in range(100, training_set.shape[0]):\n",
    "#    X_train.append(training_set_scaled[i-100:i, 0])\n",
    "#    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "print('X_train shape == {}.'.format(X_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Neural Network based on LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Adding 1st LSTM layer\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(n_past, dataset_train.shape[1]-1)))\n",
    "\n",
    "# Adding 2nd LSTM layer\n",
    "model.add(LSTM(units=10, return_sequences=False))\n",
    "\n",
    "# Adding Dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Compiling the Neural Network\n",
    "model.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 1: val_loss did not improve from inf\n",
      "4/4 [==============================] - 3s 302ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 2: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 100ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 3: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 93ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 4: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 91ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 5: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 6: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 90ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 7: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 95ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 8: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 9: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 94ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - ETA: 0s - loss: nan\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 10: val_loss did not improve from inf\n",
      "4/4 [==============================] - 0s 92ms/step - loss: nan - val_loss: nan - lr: 0.0100\n",
      "Epoch 10: early stopping\n",
      "CPU times: user 14.5 s, sys: 4.88 s, total: 19.4 s\n",
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tb = TensorBoard('logs')\n",
    "\n",
    "history = model.fit(X_train, y_train, shuffle=True, epochs=30, callbacks=[es, rlr, mcp, tb], validation_split=0.1, verbose=1, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 5s 60ms/step - loss: nan\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: nan\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: nan\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: nan\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: nan\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: nan\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 2s 61ms/step - loss: nan\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: nan\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: nan\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 2s 66ms/step - loss: nan\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 2s 69ms/step - loss: nan\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 3s 76ms/step - loss: nan\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 3s 75ms/step - loss: nan\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 2s 69ms/step - loss: nan\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 2s 68ms/step - loss: nan\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 2s 69ms/step - loss: nan\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 2s 69ms/step - loss: nan\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 2s 69ms/step - loss: nan\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 3s 71ms/step - loss: nan\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 3s 71ms/step - loss: nan\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 3s 75ms/step - loss: nan\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 3s 75ms/step - loss: nan\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: nan\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 3s 72ms/step - loss: nan\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: nan\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 3s 75ms/step - loss: nan\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: nan\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: nan\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 3s 76ms/step - loss: nan\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 3s 77ms/step - loss: nan\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 3s 77ms/step - loss: nan\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 3s 75ms/step - loss: nan\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 3s 76ms/step - loss: nan\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 3s 78ms/step - loss: nan\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 3s 80ms/step - loss: nan\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 3s 78ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff29a33ab80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NEURONS_FirstLayer = 128\n",
    "NUM_NEURONS_SecondLayer = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=NUM_NEURONS_FirstLayer,return_sequences=True,input_shape=(X_train.shape[1], 1)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=NUM_NEURONS_SecondLayer,return_sequences=True, input_shape=(NUM_NEURONS_FirstLayer,1)))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=50,return_sequences=True))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(units=50))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer = Adam(learning_rate=0.01),loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
